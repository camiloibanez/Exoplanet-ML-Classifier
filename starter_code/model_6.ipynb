{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\camilo\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\camilo\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.16.5)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\camilo\\anaconda3\\lib\\site-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>874.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5455</td>\n",
       "      <td>81</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>31.04</td>\n",
       "      <td>-10.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5853</td>\n",
       "      <td>158</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>33.46</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>668.95</td>\n",
       "      <td>-230.35</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5805</td>\n",
       "      <td>157</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>603.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>874.33</td>\n",
       "      <td>-314.24</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6031</td>\n",
       "      <td>169</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>686.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>420.33</td>\n",
       "      <td>-136.70</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6046</td>\n",
       "      <td>189</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  ...  koi_srad_err2         ra        dec  koi_kepmag\n",
       "0       CONFIRMED              0              0              0  ...         -0.061  291.93423  48.141651      15.347\n",
       "1  FALSE POSITIVE              0              1              0  ...         -0.078  297.00482  48.134129      15.436\n",
       "2  FALSE POSITIVE              0              1              0  ...         -0.067  285.53461  48.285210      15.597\n",
       "3       CONFIRMED              0              0              0  ...         -0.133  288.75488  48.226200      15.509\n",
       "4       CONFIRMED              0              0              0  ...         -0.105  296.28613  48.224670      15.714\n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
    "       'koi_fpflag_ec', 'koi_period', 'koi_time0bk', 'koi_impact',\n",
    "       'koi_duration', 'koi_depth', 'koi_prad', 'koi_teq', 'koi_insol',\n",
    "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_slogg',\n",
    "       'koi_srad', 'ra', 'dec', 'koi_kepmag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"koi_disposition\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6991,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values.reshape(-1,)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Camilo\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Camilo\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Camilo\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Camilo\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.185090</td>\n",
       "      <td>133.294014</td>\n",
       "      <td>0.465</td>\n",
       "      <td>4.80188</td>\n",
       "      <td>423280.0</td>\n",
       "      <td>92.50</td>\n",
       "      <td>1564</td>\n",
       "      <td>1414.18</td>\n",
       "      <td>1909.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6516</td>\n",
       "      <td>4.249</td>\n",
       "      <td>1.279</td>\n",
       "      <td>295.39136</td>\n",
       "      <td>40.216770</td>\n",
       "      <td>15.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.592634</td>\n",
       "      <td>132.328769</td>\n",
       "      <td>0.877</td>\n",
       "      <td>8.94880</td>\n",
       "      <td>155160.0</td>\n",
       "      <td>100.20</td>\n",
       "      <td>2255</td>\n",
       "      <td>6128.09</td>\n",
       "      <td>1207.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6574</td>\n",
       "      <td>4.061</td>\n",
       "      <td>1.768</td>\n",
       "      <td>291.76633</td>\n",
       "      <td>37.097191</td>\n",
       "      <td>14.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.609654</td>\n",
       "      <td>134.388290</td>\n",
       "      <td>0.213</td>\n",
       "      <td>2.21800</td>\n",
       "      <td>63.2</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1550</td>\n",
       "      <td>1365.41</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "      <td>5418</td>\n",
       "      <td>3.447</td>\n",
       "      <td>4.233</td>\n",
       "      <td>291.02719</td>\n",
       "      <td>37.613911</td>\n",
       "      <td>12.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.288868</td>\n",
       "      <td>132.377610</td>\n",
       "      <td>0.534</td>\n",
       "      <td>2.59900</td>\n",
       "      <td>59.3</td>\n",
       "      <td>0.57</td>\n",
       "      <td>944</td>\n",
       "      <td>187.43</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5374</td>\n",
       "      <td>4.555</td>\n",
       "      <td>0.721</td>\n",
       "      <td>288.83136</td>\n",
       "      <td>47.551991</td>\n",
       "      <td>13.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.237490</td>\n",
       "      <td>170.819140</td>\n",
       "      <td>0.128</td>\n",
       "      <td>1.81190</td>\n",
       "      <td>315.8</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.17</td>\n",
       "      <td>30.7</td>\n",
       "      <td>1</td>\n",
       "      <td>5265</td>\n",
       "      <td>4.580</td>\n",
       "      <td>0.810</td>\n",
       "      <td>290.00757</td>\n",
       "      <td>42.116459</td>\n",
       "      <td>15.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  ...  koi_srad         ra        dec  koi_kepmag\n",
       "3714              0              1              0              0  ...     1.279  295.39136  40.216770      15.519\n",
       "3891              0              1              0              0  ...     1.768  291.76633  37.097191      14.915\n",
       "5464              0              0              0              0  ...     4.233  291.02719  37.613911      12.765\n",
       "1775              0              0              0              0  ...     0.721  288.83136  47.551991      13.851\n",
       "133               0              0              0              0  ...     0.810  290.00757  42.116459      15.001\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=20))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=500, activation='relu'))\n",
    "model.add(Dense(units=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001A32EE52C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001A32EE52C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "175/175 - 1s - loss: 0.4574 - accuracy: 0.7407\n",
      "Epoch 2/100\n",
      "175/175 - 1s - loss: 0.3816 - accuracy: 0.7854\n",
      "Epoch 3/100\n",
      "175/175 - 1s - loss: 0.3804 - accuracy: 0.7977\n",
      "Epoch 4/100\n",
      "175/175 - 1s - loss: 0.3708 - accuracy: 0.7977\n",
      "Epoch 5/100\n",
      "175/175 - 1s - loss: 0.3726 - accuracy: 0.7963\n",
      "Epoch 6/100\n",
      "175/175 - 1s - loss: 0.3730 - accuracy: 0.7970\n",
      "Epoch 7/100\n",
      "175/175 - 1s - loss: 0.3600 - accuracy: 0.8076\n",
      "Epoch 8/100\n",
      "175/175 - 1s - loss: 0.3605 - accuracy: 0.8103\n",
      "Epoch 9/100\n",
      "175/175 - 1s - loss: 0.3656 - accuracy: 0.8069\n",
      "Epoch 10/100\n",
      "175/175 - 1s - loss: 0.3574 - accuracy: 0.8124\n",
      "Epoch 11/100\n",
      "175/175 - 1s - loss: 0.3575 - accuracy: 0.8044\n",
      "Epoch 12/100\n",
      "175/175 - 1s - loss: 0.3539 - accuracy: 0.8133\n",
      "Epoch 13/100\n",
      "175/175 - 1s - loss: 0.3540 - accuracy: 0.8122\n",
      "Epoch 14/100\n",
      "175/175 - 1s - loss: 0.3496 - accuracy: 0.8183\n",
      "Epoch 15/100\n",
      "175/175 - 1s - loss: 0.3488 - accuracy: 0.8192\n",
      "Epoch 16/100\n",
      "175/175 - 1s - loss: 0.3449 - accuracy: 0.8214\n",
      "Epoch 17/100\n",
      "175/175 - 1s - loss: 0.3443 - accuracy: 0.8217\n",
      "Epoch 18/100\n",
      "175/175 - 1s - loss: 0.3417 - accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "175/175 - 1s - loss: 0.3378 - accuracy: 0.8265\n",
      "Epoch 20/100\n",
      "175/175 - 1s - loss: 0.3344 - accuracy: 0.8274\n",
      "Epoch 21/100\n",
      "175/175 - 1s - loss: 0.3344 - accuracy: 0.8274\n",
      "Epoch 22/100\n",
      "175/175 - 1s - loss: 0.3366 - accuracy: 0.8256\n",
      "Epoch 23/100\n",
      "175/175 - 1s - loss: 0.3295 - accuracy: 0.8307\n",
      "Epoch 24/100\n",
      "175/175 - 1s - loss: 0.3332 - accuracy: 0.8264\n",
      "Epoch 25/100\n",
      "175/175 - 1s - loss: 0.3280 - accuracy: 0.8349\n",
      "Epoch 26/100\n",
      "175/175 - 1s - loss: 0.3258 - accuracy: 0.8358\n",
      "Epoch 27/100\n",
      "175/175 - 1s - loss: 0.3208 - accuracy: 0.8399\n",
      "Epoch 28/100\n",
      "175/175 - 1s - loss: 0.3199 - accuracy: 0.8401\n",
      "Epoch 29/100\n",
      "175/175 - 1s - loss: 0.3184 - accuracy: 0.8403\n",
      "Epoch 30/100\n",
      "175/175 - 1s - loss: 0.3236 - accuracy: 0.8339\n",
      "Epoch 31/100\n",
      "175/175 - 1s - loss: 0.3216 - accuracy: 0.8437\n",
      "Epoch 32/100\n",
      "175/175 - 1s - loss: 0.3296 - accuracy: 0.8371\n",
      "Epoch 33/100\n",
      "175/175 - 1s - loss: 0.3135 - accuracy: 0.8441\n",
      "Epoch 34/100\n",
      "175/175 - 1s - loss: 0.3171 - accuracy: 0.8364\n",
      "Epoch 35/100\n",
      "175/175 - 1s - loss: 0.3103 - accuracy: 0.8382\n",
      "Epoch 36/100\n",
      "175/175 - 1s - loss: 0.3077 - accuracy: 0.8439\n",
      "Epoch 37/100\n",
      "175/175 - 1s - loss: 0.3032 - accuracy: 0.8459\n",
      "Epoch 38/100\n",
      "175/175 - 1s - loss: 0.3001 - accuracy: 0.8466\n",
      "Epoch 39/100\n",
      "175/175 - 1s - loss: 0.2986 - accuracy: 0.8467\n",
      "Epoch 40/100\n",
      "175/175 - 1s - loss: 0.2970 - accuracy: 0.8534\n",
      "Epoch 41/100\n",
      "175/175 - 1s - loss: 0.2951 - accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "175/175 - 1s - loss: 0.2969 - accuracy: 0.8541\n",
      "Epoch 43/100\n",
      "175/175 - 1s - loss: 0.2970 - accuracy: 0.8514\n",
      "Epoch 44/100\n",
      "175/175 - 1s - loss: 0.2953 - accuracy: 0.8487\n",
      "Epoch 45/100\n",
      "175/175 - 1s - loss: 0.2892 - accuracy: 0.8566\n",
      "Epoch 46/100\n",
      "175/175 - 1s - loss: 0.2893 - accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "175/175 - 1s - loss: 0.2864 - accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "175/175 - 1s - loss: 0.2848 - accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "175/175 - 1s - loss: 0.2793 - accuracy: 0.8625\n",
      "Epoch 50/100\n",
      "175/175 - 1s - loss: 0.2754 - accuracy: 0.8621\n",
      "Epoch 51/100\n",
      "175/175 - 1s - loss: 0.2784 - accuracy: 0.8616\n",
      "Epoch 52/100\n",
      "175/175 - 1s - loss: 0.2802 - accuracy: 0.8568\n",
      "Epoch 53/100\n",
      "175/175 - 1s - loss: 0.2792 - accuracy: 0.8621\n",
      "Epoch 54/100\n",
      "175/175 - 1s - loss: 0.2720 - accuracy: 0.8639\n",
      "Epoch 55/100\n",
      "175/175 - 1s - loss: 0.2684 - accuracy: 0.8670\n",
      "Epoch 56/100\n",
      "175/175 - 1s - loss: 0.2738 - accuracy: 0.8684\n",
      "Epoch 57/100\n",
      "175/175 - 1s - loss: 0.2702 - accuracy: 0.8602\n",
      "Epoch 58/100\n",
      "175/175 - 1s - loss: 0.2605 - accuracy: 0.8727\n",
      "Epoch 59/100\n",
      "175/175 - 1s - loss: 0.2635 - accuracy: 0.8680\n",
      "Epoch 60/100\n",
      "175/175 - 1s - loss: 0.2686 - accuracy: 0.8619\n",
      "Epoch 61/100\n",
      "175/175 - 1s - loss: 0.2590 - accuracy: 0.8680\n",
      "Epoch 62/100\n",
      "175/175 - 1s - loss: 0.2574 - accuracy: 0.8666\n",
      "Epoch 63/100\n",
      "175/175 - 1s - loss: 0.2682 - accuracy: 0.8734\n",
      "Epoch 64/100\n",
      "175/175 - 1s - loss: 0.2603 - accuracy: 0.8678\n",
      "Epoch 65/100\n",
      "175/175 - 1s - loss: 0.2523 - accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "175/175 - 1s - loss: 0.2508 - accuracy: 0.8775\n",
      "Epoch 67/100\n",
      "175/175 - 1s - loss: 0.2492 - accuracy: 0.8741\n",
      "Epoch 68/100\n",
      "175/175 - 1s - loss: 0.2580 - accuracy: 0.8727\n",
      "Epoch 69/100\n",
      "175/175 - 1s - loss: 0.2489 - accuracy: 0.8773\n",
      "Epoch 70/100\n",
      "175/175 - 1s - loss: 0.2492 - accuracy: 0.8809\n",
      "Epoch 71/100\n",
      "175/175 - 1s - loss: 0.2416 - accuracy: 0.8841\n",
      "Epoch 72/100\n",
      "175/175 - 1s - loss: 0.2389 - accuracy: 0.8823\n",
      "Epoch 73/100\n",
      "175/175 - 1s - loss: 0.2361 - accuracy: 0.8857\n",
      "Epoch 74/100\n",
      "175/175 - 1s - loss: 0.2382 - accuracy: 0.8857\n",
      "Epoch 75/100\n",
      "175/175 - 1s - loss: 0.2370 - accuracy: 0.8881\n",
      "Epoch 76/100\n",
      "175/175 - 1s - loss: 0.2385 - accuracy: 0.8805\n",
      "Epoch 77/100\n",
      "175/175 - 1s - loss: 0.2293 - accuracy: 0.8891\n",
      "Epoch 78/100\n",
      "175/175 - 1s - loss: 0.2317 - accuracy: 0.8898\n",
      "Epoch 79/100\n",
      "175/175 - 1s - loss: 0.2198 - accuracy: 0.8929\n",
      "Epoch 80/100\n",
      "175/175 - 1s - loss: 0.2193 - accuracy: 0.8952\n",
      "Epoch 81/100\n",
      "175/175 - 1s - loss: 0.2319 - accuracy: 0.8947\n",
      "Epoch 82/100\n",
      "175/175 - 1s - loss: 0.2218 - accuracy: 0.8911\n",
      "Epoch 83/100\n",
      "175/175 - 1s - loss: 0.2208 - accuracy: 0.8945\n",
      "Epoch 84/100\n",
      "175/175 - 1s - loss: 0.2209 - accuracy: 0.8991\n",
      "Epoch 85/100\n",
      "175/175 - 1s - loss: 0.2157 - accuracy: 0.9006\n",
      "Epoch 86/100\n",
      "175/175 - 1s - loss: 0.2238 - accuracy: 0.8956\n",
      "Epoch 87/100\n",
      "175/175 - 1s - loss: 0.2391 - accuracy: 0.8868\n",
      "Epoch 88/100\n",
      "175/175 - 1s - loss: 0.2131 - accuracy: 0.9008\n",
      "Epoch 89/100\n",
      "175/175 - 1s - loss: 0.2199 - accuracy: 0.8911\n",
      "Epoch 90/100\n",
      "175/175 - 1s - loss: 0.2116 - accuracy: 0.8972\n",
      "Epoch 91/100\n",
      "175/175 - 1s - loss: 0.2130 - accuracy: 0.9004\n",
      "Epoch 92/100\n",
      "175/175 - 1s - loss: 0.2064 - accuracy: 0.9031\n",
      "Epoch 93/100\n",
      "175/175 - 1s - loss: 0.2129 - accuracy: 0.9040\n",
      "Epoch 94/100\n",
      "175/175 - 1s - loss: 0.2092 - accuracy: 0.9018\n",
      "Epoch 95/100\n",
      "175/175 - 1s - loss: 0.2063 - accuracy: 0.9074\n",
      "Epoch 96/100\n",
      "175/175 - 1s - loss: 0.2047 - accuracy: 0.9050\n",
      "Epoch 97/100\n",
      "175/175 - 1s - loss: 0.2076 - accuracy: 0.9022\n",
      "Epoch 98/100\n",
      "175/175 - 1s - loss: 0.2088 - accuracy: 0.9040\n",
      "Epoch 99/100\n",
      "175/175 - 1s - loss: 0.1969 - accuracy: 0.9079\n",
      "Epoch 100/100\n",
      "175/175 - 1s - loss: 0.1980 - accuracy: 0.9133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a32eecb688>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,\n",
    "         y_train_categorical,\n",
    "         epochs=100,\n",
    "         shuffle=True,\n",
    "         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001A33003C4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001A33003C4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9213\n",
      "Training Data Score: [0.17091116309165955, 0.9213161468505859]\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8856\n",
      "Testing Data Score: [0.39586320519447327, 0.8856325745582581]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.evaluate(X_train_scaled, y_train_categorical)}\")\n",
    "print(f\"Testing Data Score: {model.evaluate(X_test_scaled, y_test_categorical)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399/1399 [==============================] - 0s 80us/sample - loss: 0.3768 - accuracy: 0.8349\n",
      "Units: 25, 25 and 25, Testing Score: [0.3767591007613045, 0.8348821]\n",
      "1399/1399 [==============================] - 0s 71us/sample - loss: 0.3857 - accuracy: 0.8356\n",
      "Units: 25, 25 and 50, Testing Score: [0.38572771428652197, 0.83559686]\n",
      "1399/1399 [==============================] - 0s 71us/sample - loss: 0.3751 - accuracy: 0.8685\n",
      "Units: 25, 25 and 75, Testing Score: [0.3751257055780562, 0.86847746]\n",
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.3780 - accuracy: 0.8442\n",
      "Units: 25, 25 and 100, Testing Score: [0.3779759629016437, 0.8441744]\n",
      "1399/1399 [==============================] - 0s 75us/sample - loss: 0.3456 - accuracy: 0.8585\n",
      "Units: 25, 50 and 25, Testing Score: [0.34556916105781305, 0.8584703]\n",
      "1399/1399 [==============================] - 0s 93us/sample - loss: 0.3873 - accuracy: 0.8563\n",
      "Units: 25, 50 and 50, Testing Score: [0.3872698115250142, 0.8563259]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.4857 - accuracy: 0.8456\n",
      "Units: 25, 50 and 75, Testing Score: [0.4856559564975264, 0.845604]\n",
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.3985 - accuracy: 0.8649\n",
      "Units: 25, 50 and 100, Testing Score: [0.39846511533466555, 0.8649035]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.3685 - accuracy: 0.8506\n",
      "Units: 25, 75 and 25, Testing Score: [0.36853210293582034, 0.8506076]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.3887 - accuracy: 0.8449\n",
      "Units: 25, 75 and 50, Testing Score: [0.38873064160091353, 0.8448892]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.4625 - accuracy: 0.8742\n",
      "Units: 25, 75 and 75, Testing Score: [0.4624791121465807, 0.8741959]\n",
      "1399/1399 [==============================] - 0s 101us/sample - loss: 0.3657 - accuracy: 0.8592\n",
      "Units: 25, 75 and 100, Testing Score: [0.3657147638537016, 0.85918516]\n",
      "1399/1399 [==============================] - 0s 81us/sample - loss: 0.3791 - accuracy: 0.8620\n",
      "Units: 25, 100 and 25, Testing Score: [0.37908765132551625, 0.86204433]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.3901 - accuracy: 0.8728\n",
      "Units: 25, 100 and 50, Testing Score: [0.39011752633131597, 0.87276626]\n",
      "1399/1399 [==============================] - 0s 79us/sample - loss: 0.3501 - accuracy: 0.8506\n",
      "Units: 25, 100 and 75, Testing Score: [0.3500839914484822, 0.8506076]\n",
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.3450 - accuracy: 0.8420\n",
      "Units: 25, 100 and 100, Testing Score: [0.3450423000624045, 0.84203005]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.3793 - accuracy: 0.8535\n",
      "Units: 50, 25 and 25, Testing Score: [0.37926924681348234, 0.85346675]\n",
      "1399/1399 [==============================] - 0s 75us/sample - loss: 0.3235 - accuracy: 0.8585\n",
      "Units: 50, 25 and 50, Testing Score: [0.3234835424706116, 0.8584703]\n",
      "1399/1399 [==============================] - 0s 80us/sample - loss: 0.3295 - accuracy: 0.8549\n",
      "Units: 50, 25 and 75, Testing Score: [0.3294616679343434, 0.85489637]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.4336 - accuracy: 0.8692\n",
      "Units: 50, 25 and 100, Testing Score: [0.4336433038381784, 0.8691923]\n",
      "1399/1399 [==============================] - 0s 225us/sample - loss: 0.3415 - accuracy: 0.8692\n",
      "Units: 50, 50 and 25, Testing Score: [0.3415047210655185, 0.8691923]\n",
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.4659 - accuracy: 0.8642\n",
      "Units: 50, 50 and 50, Testing Score: [0.46588208625962513, 0.86418873]\n",
      "1399/1399 [==============================] - 0s 163us/sample - loss: 0.4879 - accuracy: 0.8563\n",
      "Units: 50, 50 and 75, Testing Score: [0.48790909691824924, 0.8563259]\n",
      "1399/1399 [==============================] - 0s 74us/sample - loss: 0.3408 - accuracy: 0.8606\n",
      "Units: 50, 50 and 100, Testing Score: [0.340801068965753, 0.8606147]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.4450 - accuracy: 0.8706\n",
      "Units: 50, 75 and 25, Testing Score: [0.44503110717500083, 0.87062186]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.4051 - accuracy: 0.8628\n",
      "Units: 50, 75 and 50, Testing Score: [0.40510580903338567, 0.8627591]\n",
      "1399/1399 [==============================] - 0s 90us/sample - loss: 0.3830 - accuracy: 0.8449\n",
      "Units: 50, 75 and 75, Testing Score: [0.38301916006124387, 0.8448892]\n",
      "1399/1399 [==============================] - 0s 206us/sample - loss: 0.4861 - accuracy: 0.8585\n",
      "Units: 50, 75 and 100, Testing Score: [0.4860814479183009, 0.8584703]\n",
      "1399/1399 [==============================] - 0s 70us/sample - loss: 0.4796 - accuracy: 0.8628\n",
      "Units: 50, 100 and 25, Testing Score: [0.4796159481090507, 0.8627591]\n",
      "1399/1399 [==============================] - 0s 90us/sample - loss: 0.3359 - accuracy: 0.8728\n",
      "Units: 50, 100 and 50, Testing Score: [0.3358760597963176, 0.87276626]\n",
      "1399/1399 [==============================] - 0s 96us/sample - loss: 0.4524 - accuracy: 0.8642\n",
      "Units: 50, 100 and 75, Testing Score: [0.4523541263761991, 0.86418873]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.3720 - accuracy: 0.8663\n",
      "Units: 50, 100 and 100, Testing Score: [0.37200166763281123, 0.86633307]\n",
      "1399/1399 [==============================] - 0s 70us/sample - loss: 0.3163 - accuracy: 0.8735\n",
      "Units: 75, 25 and 25, Testing Score: [0.31633142038402257, 0.87348104]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.3517 - accuracy: 0.8663\n",
      "Units: 75, 25 and 50, Testing Score: [0.35167933784270816, 0.86633307]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.3962 - accuracy: 0.8756\n",
      "Units: 75, 25 and 75, Testing Score: [0.39618137390422686, 0.87562543]\n",
      "1399/1399 [==============================] - 0s 71us/sample - loss: 0.4247 - accuracy: 0.8570\n",
      "Units: 75, 25 and 100, Testing Score: [0.4246710355342329, 0.85704076]\n",
      "1399/1399 [==============================] - 0s 75us/sample - loss: 0.4463 - accuracy: 0.8649\n",
      "Units: 75, 50 and 25, Testing Score: [0.4462871721508334, 0.8649035]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.4822 - accuracy: 0.8656\n",
      "Units: 75, 50 and 50, Testing Score: [0.48215655138911817, 0.8656183]\n",
      "1399/1399 [==============================] - 0s 96us/sample - loss: 0.3953 - accuracy: 0.8799\n",
      "Units: 75, 50 and 75, Testing Score: [0.3953081220920977, 0.8799142]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.4060 - accuracy: 0.8763\n",
      "Units: 75, 50 and 100, Testing Score: [0.4059855575813746, 0.87634027]\n",
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.4033 - accuracy: 0.8713\n",
      "Units: 75, 75 and 25, Testing Score: [0.40329780071185606, 0.8713367]\n",
      "1399/1399 [==============================] - 0s 74us/sample - loss: 0.4337 - accuracy: 0.8821\n",
      "Units: 75, 75 and 50, Testing Score: [0.43374641143781445, 0.8820586]\n",
      "1399/1399 [==============================] - 0s 100us/sample - loss: 0.5620 - accuracy: 0.8685\n",
      "Units: 75, 75 and 75, Testing Score: [0.5620111201259389, 0.86847746]\n",
      "1399/1399 [==============================] - 0s 177us/sample - loss: 0.4247 - accuracy: 0.8663\n",
      "Units: 75, 75 and 100, Testing Score: [0.42467173647463025, 0.86633307]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.4045 - accuracy: 0.8728\n",
      "Units: 75, 100 and 25, Testing Score: [0.40453439811411035, 0.87276626]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.4416 - accuracy: 0.8592\n",
      "Units: 75, 100 and 50, Testing Score: [0.44159706404500554, 0.85918516]\n",
      "1399/1399 [==============================] - 0s 72us/sample - loss: 0.5071 - accuracy: 0.8642\n",
      "Units: 75, 100 and 75, Testing Score: [0.5070687134439302, 0.86418873]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.4236 - accuracy: 0.8785\n",
      "Units: 75, 100 and 100, Testing Score: [0.42360502987397064, 0.8784846]\n",
      "1399/1399 [==============================] - 0s 73us/sample - loss: 0.3314 - accuracy: 0.8663\n",
      "Units: 100, 25 and 25, Testing Score: [0.33136456489051724, 0.86633307]\n",
      "1399/1399 [==============================] - 0s 68us/sample - loss: 0.3513 - accuracy: 0.8828\n",
      "Units: 100, 25 and 50, Testing Score: [0.3513106540473893, 0.8827734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.3363 - accuracy: 0.8806\n",
      "Units: 100, 25 and 75, Testing Score: [0.3362629815584596, 0.880629]\n",
      "1399/1399 [==============================] - 0s 71us/sample - loss: 0.2951 - accuracy: 0.8828\n",
      "Units: 100, 25 and 100, Testing Score: [0.2951388275350648, 0.8827734]\n",
      "1399/1399 [==============================] - 0s 81us/sample - loss: 0.3492 - accuracy: 0.8799\n",
      "Units: 100, 50 and 25, Testing Score: [0.34920484715908917, 0.8799142]\n",
      "1399/1399 [==============================] - 0s 79us/sample - loss: 0.3867 - accuracy: 0.8735\n",
      "Units: 100, 50 and 50, Testing Score: [0.3867258852064141, 0.87348104]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.3437 - accuracy: 0.8699\n",
      "Units: 100, 50 and 75, Testing Score: [0.34372500191210337, 0.8699071]\n",
      "1399/1399 [==============================] - 0s 70us/sample - loss: 0.3496 - accuracy: 0.8806\n",
      "Units: 100, 50 and 100, Testing Score: [0.3496028831850383, 0.880629]\n",
      "1399/1399 [==============================] - 0s 74us/sample - loss: 0.3950 - accuracy: 0.8749\n",
      "Units: 100, 75 and 25, Testing Score: [0.3950169139712772, 0.87491065]\n",
      "1399/1399 [==============================] - 0s 76us/sample - loss: 0.4188 - accuracy: 0.8670\n",
      "Units: 100, 75 and 50, Testing Score: [0.41879699239141177, 0.8670479]\n",
      "1399/1399 [==============================] - 0s 80us/sample - loss: 0.5073 - accuracy: 0.8713\n",
      "Units: 100, 75 and 75, Testing Score: [0.5072784069459553, 0.8713367]\n",
      "1399/1399 [==============================] - 0s 77us/sample - loss: 0.4014 - accuracy: 0.8506\n",
      "Units: 100, 75 and 100, Testing Score: [0.4013665812815659, 0.8506076]\n",
      "1399/1399 [==============================] - 0s 70us/sample - loss: 0.3724 - accuracy: 0.8849\n",
      "Units: 100, 100 and 25, Testing Score: [0.37244913132170254, 0.8849178]\n",
      "1399/1399 [==============================] - 0s 75us/sample - loss: 0.3574 - accuracy: 0.8849\n",
      "Units: 100, 100 and 50, Testing Score: [0.3574371629949124, 0.8849178]\n",
      "1399/1399 [==============================] - 0s 71us/sample - loss: 0.5241 - accuracy: 0.8742\n",
      "Units: 100, 100 and 75, Testing Score: [0.5241321687552655, 0.8741959]\n",
      "1399/1399 [==============================] - 0s 69us/sample - loss: 0.6207 - accuracy: 0.8813\n",
      "Units: 100, 100 and 100, Testing Score: [0.6206937660226829, 0.88134384]\n"
     ]
    }
   ],
   "source": [
    "list = [25, 50, 75, 100]\n",
    "\n",
    "for i in list:\n",
    "    for x in list:\n",
    "        for y in list:\n",
    "            model2 = Sequential()\n",
    "\n",
    "            model2.add(Dense(units=i, activation='relu', input_dim=20))\n",
    "            model2.add(Dense(units=x, activation='relu'))\n",
    "            model2.add(Dense(units=y, activation='relu'))\n",
    "            model2.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "            model2.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "            model2.fit(X_train_scaled,\n",
    "             y_train_categorical,\n",
    "             epochs=100,\n",
    "             shuffle=True,\n",
    "             verbose=0)\n",
    "\n",
    "            print(f\"Units: {i}, {x} and {y}, Testing Score: {model2.evaluate(X_test_scaled, y_test_categorical)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'your_name.sav'\n",
    "joblib.dump(your_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
