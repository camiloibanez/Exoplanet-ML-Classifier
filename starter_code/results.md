A decision tree classifier with max_depth of 5 resulted in 0.878.

A random forest classifier with max_depth of 18, min_samples_split of 3, and n_estimators of 500 resulted in 0.899.

A K nearest neighbors with n_neighbors of 11 resulted in 0.800.

A neural network of one layer with 100 units resulted in 0.863.

A neural network of two layers with 100 units and 100 units resulted in 0.862.

A neural network of three layers with 100 units, 100 units and 50 units resulted in 0.884.

A neural network of three layers with 100 units, 300 units and 100 units resulted in 0.868.

A neural network of five layers with 100 units, 300 units, 500 units, 300 units and 100 units resulted in 0.871.

A neural network of seven layers with Dense:100, Dense:300, Dropout:0.2, Dense:500, Dense:300, Dropout:0.2 and Dense:100 resulted in 0.886.

A Gaussian Naive Bayes classifier resulted in 0.716.

A Multi-layer Perceptron Classifier resulted in 0.796.

A Linear Support Vector Classification resulted in 0.807.

An Extra Tree Classifier resulted in 0.845.